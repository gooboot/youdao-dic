#!/usr/bin/env python3
import json
import os
from typing import Dict, List, Set

def extract_unique_words():
    """
    ä»å½“å‰ç›®å½•ä¸­çš„æ‰€æœ‰JSONæ–‡ä»¶ä¸­æå–å”¯ä¸€å•è¯ï¼Œ
    ä¿æŒåŸæœ‰çš„JSONæ ¼å¼ï¼Œå»é™¤é‡å¤å•è¯
    """

    # è·å–å½“å‰ç›®å½•ä¸­çš„æ‰€æœ‰JSONæ–‡ä»¶
    json_files = [f for f in os.listdir('.') if f.endswith('.json')]

    if not json_files:
        print("æœªæ‰¾åˆ°JSONæ–‡ä»¶")
        return

    unique_words: Dict[str, dict] = {}  # ä½¿ç”¨å­—å…¸å­˜å‚¨å”¯ä¸€å•è¯ï¼Œkeyä¸ºheadWord
    seen_words: Set[str] = set()  # ç”¨äºå¿«é€ŸæŸ¥é‡
    total_processed = 0

    print(f"æ‰¾åˆ° {len(json_files)} ä¸ªJSONæ–‡ä»¶ï¼Œå¼€å§‹å¤„ç†...")
    print("=" * 50)

    for file_index, json_file in enumerate(json_files, 1):
        # æ˜¾ç¤ºæ–‡ä»¶å¤„ç†è¿›åº¦
        file_progress = f"[{file_index}/{len(json_files)}]"
        print(f"{file_progress} å¤„ç†æ–‡ä»¶: {json_file}")

        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                lines = f.readlines()

            words_data = []
            for line in lines:
                line = line.strip()
                if line:
                    try:
                        word_obj = json.loads(line)
                        words_data.append(word_obj)
                    except json.JSONDecodeError:
                        continue

            file_word_count = len(words_data)
            file_unique_count = 0

            # å¤„ç†å•ä¸ªæ–‡ä»¶ä¸­çš„å•è¯ï¼Œæ˜¾ç¤ºè¿›åº¦
            for word_index, word_obj in enumerate(words_data, 1):
                if not isinstance(word_obj, dict):
                    continue

                head_word = word_obj.get('headWord', '').lower()  # è½¬ä¸ºå°å†™è¿›è¡Œæ¯”è¾ƒ

                if head_word and head_word not in seen_words:
                    seen_words.add(head_word)
                    unique_words[head_word] = word_obj
                    file_unique_count += 1

                total_processed += 1

                # æ¯å¤„ç†50ä¸ªå•è¯æ˜¾ç¤ºä¸€æ¬¡è¿›åº¦
                if word_index % 50 == 0 or word_index == file_word_count:
                    word_progress = (word_index / file_word_count) * 100
                    print(f"  ğŸ“Š å¤„ç†è¿›åº¦: {word_index}/{file_word_count} ({word_progress:.1f}%)", end='\r')

            print()  # æ¢è¡Œ
            print(f"  âœ… å®Œæˆ: æ€»å•è¯ {file_word_count}, æ–°å¢å”¯ä¸€å•è¯ {file_unique_count}")

        except FileNotFoundError:
            print(f"  âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ–‡ä»¶ {json_file}")
        except Exception as e:
            print(f"  âŒ é”™è¯¯: å¤„ç† {json_file} æ—¶å‡ºç°é—®é¢˜: {e}")

    print("=" * 50)
    print("ğŸ”„ æ•´ç†æ•°æ®ä¸­...")

    # å°†å”¯ä¸€å•è¯è½¬æ¢ä¸ºåˆ—è¡¨æ ¼å¼
    unique_words_list = list(unique_words.values())

    # æŒ‰ç…§wordRankæ’åºï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    unique_words_list.sort(key=lambda x: x.get('wordRank', float('inf')))

    print("ğŸ“ é‡æ–°åˆ†é…åºå·...")
    # é‡æ–°åˆ†é…wordRankï¼Œæ˜¾ç¤ºè¿›åº¦
    total_words = len(unique_words_list)
    for i, word_obj in enumerate(unique_words_list, 1):
        word_obj['wordRank'] = i

        # æ¯å¤„ç†1000ä¸ªå•è¯æ˜¾ç¤ºä¸€æ¬¡è¿›åº¦
        if i % 1000 == 0 or i == total_words:
            progress = (i / total_words) * 100
            print(f"  è¿›åº¦: {i}/{total_words} ({progress:.1f}%)", end='\r')

    print()  # æ¢è¡Œ

    # ä¿å­˜åˆ°æ–°æ–‡ä»¶
    output_dir = os.path.expanduser('~/Desktop/myNote/')
    os.makedirs(output_dir, exist_ok=True)  # ç¡®ä¿ç›®å½•å­˜åœ¨
    output_file = os.path.join(output_dir, 'unique_words.json')
    print(f"ğŸ’¾ ä¿å­˜åˆ°æ–‡ä»¶: {output_file}")

    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(unique_words_list, f, ensure_ascii=False, indent=2)

        print("=" * 50)
        print("âœ¨ å¤„ç†å®Œæˆ!")
        print(f"ğŸ“ å¤„ç†çš„æ–‡ä»¶æ•°é‡: {len(json_files)}")
        print(f"ğŸ“Š åŸå§‹å•è¯æ€»æ•°: {total_processed}")
        print(f"ğŸ¯ å”¯ä¸€å•è¯æ•°é‡: {len(unique_words_list)}")
        if total_processed > 0:
            print(f"ğŸ—‚ï¸  å»é‡æ¯”ä¾‹: {((total_processed - len(unique_words_list)) / total_processed * 100):.1f}%")
        else:
            print("ğŸ—‚ï¸  å»é‡æ¯”ä¾‹: 0.0%")
        print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {output_file}")

    except Exception as e:
        print(f"âŒ é”™è¯¯: ä¿å­˜æ–‡ä»¶æ—¶å‡ºç°é—®é¢˜: {e}")

if __name__ == "__main__":
    extract_unique_words()